{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python_defaultSpec_1599501621081",
   "display_name": "Python 3.7.7 64-bit ('base': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytorch_lightning as pl\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "import foolbox as fb\n",
    "import torchvision\n",
    "from torchvision.datasets import CIFAR10\n",
    "from pytorch_lightning.loggers import TensorBoardLogger\n",
    "from torch.nn.utils import prune\n",
    "from copy import deepcopy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CIFARCLassifier(pl.LightningModule):\n",
    "    def __init__(self):\n",
    "        super(CIFARCLassifier, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 32, 5, padding=2)\n",
    "        self.bn1 = nn.BatchNorm2d(32)\n",
    "        self.pool = nn.MaxPool2d(3, stride=2, padding=1)\n",
    "        self.conv2 = nn.Conv2d(32, 16, 5, padding=2)\n",
    "        self.bn2 = nn.BatchNorm2d(16)\n",
    "        self.conv3 = nn.Conv2d(16, 32, 5, padding=2)\n",
    "        self.bn3 = nn.BatchNorm2d(32)\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.fc1 = nn.Linear(32 * 4 * 4, 128)\n",
    "        self.do1 = nn.Dropout(0.25)\n",
    "        self.fc2 = nn.Linear(128, 10)\n",
    "        self.cw = fb.attacks.L2CarliniWagnerAttack()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(self.bn1(F.relu(self.conv1(x))))\n",
    "        x = self.pool(self.bn2(F.relu(self.conv2(x))))\n",
    "        x = self.pool(self.bn3(F.relu(self.conv3(x))))\n",
    "        x = self.flatten(x)\n",
    "        x = self.do1(F.relu(self.fc1(x)))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        return F.log_softmax(x, dim=1)\n",
    "\n",
    "\n",
    "    def perform_pruning(self):\n",
    "        prune.random_unstructured(module=self.fc1, name='weight', amount=0.2)\n",
    "\n",
    "\n",
    "    def prepare_data(self):\n",
    "        #download the data, augment and normalize them\n",
    "        self.cifar_train = CIFAR10(root=\"data/\", train=True, transform=torchvision.transforms.Compose([torchvision.transforms.ToTensor(), torchvision.transforms.Normalize(0.5, 0.5)]))\n",
    "\n",
    "        self.cifar_val = CIFAR10(root=\"data/\", train=False, transform=torchvision.transforms.Compose([ torchvision.transforms.ToTensor(), torchvision.transforms.Normalize(0.5, 0.5)]))\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        return torch.utils.data.DataLoader(self.cifar_train, batch_size=128, shuffle=True, num_workers=12)\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        return torch.utils.data.DataLoader(self.cifar_val, batch_size=128, shuffle=False, num_workers=12)\n",
    "\n",
    "    def training_step(self, train_batch, batch_idx):\n",
    "        #1 batch of training\n",
    "        data, label = train_batch\n",
    "        out = self.forward(data)\n",
    "        loss = F.nll_loss(out, label)\n",
    "        prediction = out.argmax(dim=1, keepdim=True).squeeze()\n",
    "\n",
    "        correct =  prediction.eq(label.view_as(prediction)).sum().item()\n",
    "        return {'loss' : loss, 'correct' : correct}\n",
    "    \n",
    "    def training_epoch_end(self, outputs):\n",
    "        #end of an epoch\n",
    "        #calculate the average loss of this epoch\n",
    "        avg_loss = torch.stack([x['loss'] for x in outputs]).mean()\n",
    "        accuracy = 100 * (sum([x['correct'] for x in outputs]) / float(len(self.cifar_train)))\n",
    "\n",
    "        logs = {'train_loss': avg_loss, 'train_accuracy': accuracy}\n",
    "        '''\n",
    "        -----------------------WARNING------------------------------------\n",
    "        at the end of the training step, set the final model as the current \n",
    "        weight set. Don't forget to zero_grad() as the attack requires using\n",
    "        the graients of the parameters, we are going to set the context to be \n",
    "        torch.enable_grad() as during the evaluation, the weight tensors are so to not\n",
    "        store the gradient information. However, when we enable the gradient\n",
    "        the gradients with respect to the training loss function are stored in\n",
    "        the tensor whereas the adversarial loss function is different, and this makes the\n",
    "        the optimization completely break apart.\n",
    "        -----------------------WARNING------------------------------------\n",
    "        ''' \n",
    "\n",
    "        return {'loss' : avg_loss, 'log' : logs}\n",
    "\n",
    "\n",
    "    def validation_step(self, validation_batch, batch_idx):\n",
    "        if batch_idx == 0:\n",
    "            torch.cuda.memory_summary()\n",
    "        \n",
    "        data, label = validation_batch\n",
    "        #standard inference\n",
    "        out = self.forward(data)\n",
    "        loss = F.nll_loss(out, label)\n",
    "        prediction = out.argmax(dim=1, keepdim=True).squeeze()\n",
    "        correct =  prediction.eq(label.view_as(prediction)).sum().item()\n",
    "\n",
    "        return {'loss' : loss, 'correct' : correct}\n",
    "\n",
    "\n",
    "    def validation_epoch_end(self, outputs):\n",
    "        #end of an epoch\n",
    "        #calculate the average loss of this epoch\n",
    "        avg_loss = torch.stack([x['loss'] for x in outputs]).mean()\n",
    "        accuracy = 100. * (sum([x['correct'] for x in outputs]) / float(len(self.cifar_val)))\n",
    "\n",
    "\n",
    "        a = list(self.conv1.named_parameters())\n",
    "\n",
    "        robust_accuracy = self.adversarial_validation()\n",
    "\n",
    "        #print(\"Total successful_attack no:{}, Total Attacks: {},  Attack Accuracy:{}\".format(succesful_attack_no, len(self.cifar_val), robust_accuracy))\n",
    "        logs = {'validation_loss': avg_loss, 'validation_accuracy': accuracy, 'robust_accuracy': robust_accuracy}\n",
    "        return {'loss' : avg_loss, 'log' : logs}\n",
    "\n",
    "\n",
    "    def adversarial_validation(self):\n",
    "        val_dataloader = self.val_dataloader()\n",
    "        self.eval()\n",
    "        adv_model = fb.PyTorchModel(self, bounds=(0,1))\n",
    "        successful_attack_sum = 0\n",
    "        \n",
    "        with torch.enable_grad():\n",
    "            for batch_id, (data, label) in enumerate(val_dataloader):\n",
    "                data, label = data.cuda(), label.cuda()\n",
    "                _, _, success = self.cw(adv_model, data, label, epsilons=[0.01])\n",
    "                successful_attack_no = torch.sum(success.long())\n",
    "                #print(\"Successful attack:{} Attack count:{} Percentage:{}\".format(successful_attack_no, len(label), float(successful_attack_no) /len(label)))\n",
    "                successful_attack_sum += successful_attack_no\n",
    "\n",
    "        self.zero_grad()\n",
    "\n",
    "        print(\"Successful attack:{} Attack count:{} Percentage:{}\".format(successful_attack_sum, len(self.cifar_val), float(successful_attack_sum) /len(self.cifar_val)))\n",
    "        robust_accuracy = 100. * (1-(float(successful_attack_sum) /len(self.cifar_val))) \n",
    "        return robust_accuracy\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        return torch.optim.SGD(self.parameters(), lr=0.01, momentum=0.9)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ThresholdPruning(prune.BasePruningMethod):\n",
    "    \n",
    "    PRUNING_TYPE = 'unstructured'\n",
    "\n",
    "    def compute_mask(self, t, default_mask):\n",
    "        mask = default_mask.clone()\n",
    "        print(mask.type())\n",
    "        with torch.no_grad():\n",
    "            uniques = torch.unique(t)\n",
    "        sorted_uniques = torch.sort(uniques)\n",
    "        lower_thresh_index = sorted_uniques[0][int(len(sorted_uniques[0]) * 0.25)]\n",
    "        upper_thresh_index = sorted_uniques[0][int(len(sorted_uniques[0]) * 0.75)]\n",
    "        mask = torch.logical_and(torch.lt(t, upper_thresh_index), torch.gt(t, lower_thresh_index)).float()\n",
    "        \n",
    "        print(mask)\n",
    "        \n",
    "        return mask\n",
    "\n",
    "def threshold_pruning(module, name):\n",
    "   ThresholdPruning.apply(module, name)\n",
    "   return module\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": "GPU available: True, used: True\nTPU available: False, using: 0 TPU cores\nCUDA_VISIBLE_DEVICES: [0]\n\n   | Name    | Type        | Params\n-----------------------------------------\n0  | conv1   | Conv2d      | 2 K   \n1  | bn1     | BatchNorm2d | 64    \n2  | pool    | MaxPool2d   | 0     \n3  | conv2   | Conv2d      | 12 K  \n4  | bn2     | BatchNorm2d | 32    \n5  | conv3   | Conv2d      | 12 K  \n6  | bn3     | BatchNorm2d | 64    \n7  | flatten | Flatten     | 0     \n8  | fc1     | Linear      | 65 K  \n9  | do1     | Dropout     | 0     \n10 | fc2     | Linear      | 1 K   \n"
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validation sanity check', layout=Layout…",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "061abeba7cb0442e8bbd06ae07d0baa9"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Successful attack:9000 Attack count:10000 Percentage:0.9\n"
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Training', layout=Layout(flex='2'), max…",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "b54e330753d546fb93b6ff11220759a0"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "7a04e3cac4e04c1dbd065f78f13be49f"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Successful attack:4054 Attack count:10000 Percentage:0.4054\n"
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "a9544ad036de422b9f1f3018663076c2"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Successful attack:3416 Attack count:10000 Percentage:0.3416\n"
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "55e8e71a3fff45a1bb9e7b8b707f12aa"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Successful attack:3061 Attack count:10000 Percentage:0.3061\n"
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "896adf339d2a40088ac42281339ea75a"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Successful attack:2822 Attack count:10000 Percentage:0.2822\n"
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "42d6ca4243a844038d929eaef8371e33"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": "Saving latest checkpoint..\nSuccessful attack:2665 Attack count:10000 Percentage:0.2665\n\nSuccessful attack:2665 Attack count:10000 Percentage:0.2665\n"
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "73.35000000000001"
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "source": [
    "model = CIFARCLassifier()\n",
    "model.prepare_data()\n",
    "logger = TensorBoardLogger('tb_logs', name=\"adversarial_cifar10_model\")\n",
    "trainer = pl.Trainer(max_epochs=5, logger=logger, gpus=[0], fast_dev_run=False)\n",
    "trainer.fit(model)\n",
    "\n",
    "model.adversarial_validation()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "torch.cuda.FloatTensor\ntensor([0., 1., 1.,  ..., 0., 0., 0.], device='cuda:0')\n"
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "Linear(in_features=512, out_features=128, bias=True)"
     },
     "metadata": {},
     "execution_count": 11
    }
   ],
   "source": [
    "threshold_pruning(model.fc1, name=\"weight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Sparsity in fc1.weight: 92.00%\n"
    }
   ],
   "source": [
    "print(\n",
    "    \"Sparsity in fc1.weight: {:.2f}%\".format(\n",
    "        100. * float(torch.sum(model.fc1.weight == 0))\n",
    "        / float(model.fc1.weight.nelement())\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "[('weight_mask', tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n        [0., 0., 0.,  ..., 0., 0., 0.],\n        [0., 0., 0.,  ..., 0., 0., 0.],\n        ...,\n        [0., 0., 0.,  ..., 0., 0., 0.],\n        [0., 0., 0.,  ..., 0., 0., 0.],\n        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0'))]\n"
    }
   ],
   "source": [
    "print(list(model.fc1.named_buffers()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = model.conv1.weight\n",
    "k = torch.zeros_like(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    uniques = torch.unique(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_uniques = torch.sort(uniques)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "600"
     },
     "metadata": {},
     "execution_count": 21
    }
   ],
   "source": [
    "int(len(sorted_uniques[0]) * 1 / 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "tensor(-0.0818, device='cuda:0') tensor(0.0760, device='cuda:0')\n"
    }
   ],
   "source": [
    "lower_thresh_index = sorted_uniques[0][int(len(sorted_uniques[0]) * 0.25)]\n",
    "upper_thresh_index = sorted_uniques[0][int(len(sorted_uniques[0]) * 0.75)]\n",
    "\n",
    "print(lower_thresh_index, upper_thresh_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "o = torch.gt(t, upper_thresh_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "tensor([[[[False, False, False, False, False],\n          [False,  True, False, False,  True],\n          [False,  True, False, False, False],\n          [False,  True, False, False,  True],\n          [False, False, False, False,  True]],\n\n         [[False,  True, False, False,  True],\n          [False,  True, False, False,  True],\n          [False,  True, False, False,  True],\n          [False,  True, False, False,  True],\n          [ True, False, False, False,  True]],\n\n         [[False,  True, False, False, False],\n          [False,  True, False, False,  True],\n          [False,  True, False, False,  True],\n          [ True,  True, False, False,  True],\n          [False, False, False,  True,  True]]],\n\n\n        [[[False,  True, False,  True, False],\n          [False,  True, False,  True, False],\n          [False,  True,  True,  True,  True],\n          [False, False, False, False, False],\n          [False, False, False, False, False]],\n\n         [[False, False, False,  True, False],\n          [False, False, False, False, False],\n          [ True,  True,  True,  True,  True],\n          [False, False, False, False, False],\n          [False, False, False, False, False]],\n\n         [[False, False, False, False, False],\n          [False, False, False, False, False],\n          [False,  True,  True,  True,  True],\n          [False, False, False, False, False],\n          [ True, False, False, False, False]]],\n\n\n        [[[False, False, False, False, False],\n          [False, False, False, False, False],\n          [False, False,  True,  True, False],\n          [False,  True,  True,  True,  True],\n          [False,  True,  True,  True, False]],\n\n         [[False, False, False, False,  True],\n          [False, False, False, False, False],\n          [False, False, False, False, False],\n          [False, False, False, False, False],\n          [False, False, False, False, False]],\n\n         [[False,  True,  True, False, False],\n          [ True,  True,  True, False,  True],\n          [ True, False, False, False, False],\n          [False, False, False, False, False],\n          [ True, False, False, False, False]]],\n\n\n        ...,\n\n\n        [[[False, False, False, False, False],\n          [False, False, False, False, False],\n          [False,  True,  True,  True,  True],\n          [ True,  True,  True, False,  True],\n          [False, False, False, False, False]],\n\n         [[False, False, False, False, False],\n          [False, False, False, False, False],\n          [False,  True,  True,  True,  True],\n          [False, False, False,  True, False],\n          [False, False, False, False, False]],\n\n         [[False, False, False, False,  True],\n          [ True, False, False, False, False],\n          [False,  True, False,  True, False],\n          [False, False, False, False, False],\n          [False, False, False, False, False]]],\n\n\n        [[[False, False, False, False, False],\n          [False, False, False, False, False],\n          [False, False, False, False, False],\n          [False, False, False, False, False],\n          [False, False, False,  True, False]],\n\n         [[False, False, False, False, False],\n          [False, False, False, False, False],\n          [False, False, False, False, False],\n          [False, False, False, False, False],\n          [ True, False, False,  True,  True]],\n\n         [[ True, False, False, False, False],\n          [ True, False, False, False, False],\n          [False, False, False, False, False],\n          [False, False, False,  True, False],\n          [ True, False, False,  True,  True]]],\n\n\n        [[[False, False, False, False, False],\n          [False, False, False, False, False],\n          [ True, False,  True, False, False],\n          [ True, False, False,  True, False],\n          [ True,  True, False,  True, False]],\n\n         [[False, False, False,  True, False],\n          [False, False, False, False, False],\n          [False, False, False,  True, False],\n          [False, False, False,  True, False],\n          [ True, False, False, False,  True]],\n\n         [[False, False, False, False, False],\n          [ True, False,  True, False, False],\n          [ True, False, False, False, False],\n          [False, False,  True, False, False],\n          [False, False, False,  True,  True]]]], device='cuda:0')"
     },
     "metadata": {},
     "execution_count": 33
    }
   ],
   "source": [
    "o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.logical_or(torch.lt(t, lower_thresh_index), torch.gt(t, upper_thresh_index)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "tensor([[[[False, False,  True,  True, False],\n          [False,  True,  True, False,  True],\n          [False,  True,  True, False, False],\n          [False,  True,  True, False,  True],\n          [False, False,  True, False,  True]],\n\n         [[False,  True,  True,  True,  True],\n          [ True,  True,  True,  True,  True],\n          [False,  True,  True,  True,  True],\n          [False,  True,  True, False,  True],\n          [ True, False,  True, False,  True]],\n\n         [[False,  True, False,  True, False],\n          [False,  True,  True,  True,  True],\n          [False,  True,  True,  True,  True],\n          [ True,  True,  True, False,  True],\n          [False, False,  True,  True,  True]]],\n\n\n        [[[False,  True, False,  True, False],\n          [False,  True, False,  True, False],\n          [False,  True,  True,  True,  True],\n          [False,  True,  True, False,  True],\n          [False,  True,  True,  True,  True]],\n\n         [[False, False,  True,  True,  True],\n          [ True, False,  True, False,  True],\n          [ True,  True,  True,  True,  True],\n          [False, False,  True,  True,  True],\n          [ True, False,  True, False,  True]],\n\n         [[False, False,  True, False, False],\n          [ True, False,  True,  True,  True],\n          [False,  True,  True,  True,  True],\n          [False, False, False, False, False],\n          [ True, False, False, False,  True]]],\n\n\n        [[[ True,  True,  True,  True,  True],\n          [ True, False, False, False, False],\n          [False, False,  True,  True, False],\n          [False,  True,  True,  True,  True],\n          [False,  True,  True,  True, False]],\n\n         [[False,  True, False, False,  True],\n          [False,  True, False,  True,  True],\n          [ True, False, False,  True, False],\n          [False,  True,  True,  True,  True],\n          [ True,  True,  True, False,  True]],\n\n         [[False,  True,  True, False, False],\n          [ True,  True,  True, False,  True],\n          [ True, False,  True,  True,  True],\n          [False,  True,  True,  True, False],\n          [ True,  True, False,  True, False]]],\n\n\n        ...,\n\n\n        [[[ True,  True,  True,  True,  True],\n          [False, False, False,  True, False],\n          [False,  True,  True,  True,  True],\n          [ True,  True,  True, False,  True],\n          [ True, False,  True,  True, False]],\n\n         [[False,  True,  True,  True, False],\n          [ True, False, False, False,  True],\n          [ True,  True,  True,  True,  True],\n          [False, False, False,  True, False],\n          [False, False, False,  True,  True]],\n\n         [[False, False, False, False,  True],\n          [ True, False, False, False, False],\n          [False,  True, False,  True, False],\n          [False, False, False, False, False],\n          [False, False,  True,  True,  True]]],\n\n\n        [[[False, False,  True, False, False],\n          [False,  True,  True,  True,  True],\n          [False,  True, False, False, False],\n          [ True,  True, False, False, False],\n          [False, False, False,  True, False]],\n\n         [[False, False, False, False,  True],\n          [False, False, False, False, False],\n          [False,  True, False, False, False],\n          [False, False, False, False, False],\n          [ True, False, False,  True,  True]],\n\n         [[ True,  True, False,  True, False],\n          [ True, False, False, False, False],\n          [False,  True,  True, False, False],\n          [False, False,  True,  True, False],\n          [ True, False, False,  True,  True]]],\n\n\n        [[[False, False, False, False,  True],\n          [ True, False, False,  True, False],\n          [ True, False,  True,  True, False],\n          [ True, False, False,  True, False],\n          [ True,  True, False,  True, False]],\n\n         [[ True, False,  True,  True,  True],\n          [False,  True, False,  True, False],\n          [False,  True, False,  True, False],\n          [False, False, False,  True, False],\n          [ True,  True, False, False,  True]],\n\n         [[False,  True, False, False,  True],\n          [ True, False,  True, False, False],\n          [ True, False,  True, False,  True],\n          [False,  True,  True, False, False],\n          [False, False, False,  True,  True]]]], device='cuda:0')"
     },
     "metadata": {},
     "execution_count": 29
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}